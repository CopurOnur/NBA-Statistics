{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PROJECT SL | Final version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_T8y_g4pEqY",
        "colab_type": "text"
      },
      "source": [
        "# Beggining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4nuu5KPMsEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4be4a2b3-06dc-4c7f-e699-2c7bdc0cc4a2"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import requests\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from scipy.stats import gaussian_kde, skew\n",
        "import seaborn\n",
        "from pickle import dump\n",
        "from pickle import load\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import SpectralEmbedding\n",
        "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
        "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso, LogisticRegression\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import normalize, StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "!pip install POT\n",
        "import ot\n",
        "\n",
        "seaborn.set()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: POT in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from POT) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from POT) (1.18.5)\n",
            "Requirement already satisfied: cython>=0.23 in /usr/local/lib/python3.6/dist-packages (from POT) (0.29.21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSybGBhaNlOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seasons = ['20'+str(i-1)+'-'+str(i) for i in range(13,20)]\n",
        "\n",
        "def get_lle_space(X, n_components, n_neighbors):\n",
        "  method = 'standard'\n",
        "\n",
        "  lle_obj = LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=n_components, method = method)\n",
        "  #lle_obj = KernelPCA(n_components=n_components, kernel='sigmoid')\n",
        "  #lle_obj = PCA(n_components=n_components)\n",
        "  lle_obj.fit(X)\n",
        "  \n",
        "  return lle_obj\n",
        "\n",
        "def df_by_season(df, season):\n",
        "  return df[df['season'] == season]\n",
        "\n",
        "def get_players_ts(df):\n",
        "  ts_columns = ['MIN','FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'OREB', 'DREB', 'AST', 'TOV', 'STL', 'BLK', 'BLKA', 'PF', 'PFD']\n",
        "  ts_num = 82\n",
        "  \n",
        "  plr_df = make_ts(df.sort_values(by=['PLAYER_ID', 'GAME_ID']), \n",
        "          id_column='PLAYER_ID', \n",
        "          columns_for_ts=ts_columns,\n",
        "          columns_to_keep=['TEAM_ID', 'GAME_ID', 'WIN'], \n",
        "          num_of_shifts=ts_num,\n",
        "          if_nan=0)\n",
        "\n",
        "  return plr_df.sort_values(by=['GAME_ID'])\n",
        "\n",
        "def colapse_ts(df):\n",
        "  tmp_df = df.copy()\n",
        "\n",
        "  for col in ts_columns:\n",
        "    for i in range(ts_num, 1, -1):\n",
        "      col_1 = str(i) + '-' + col\n",
        "      col_2 = str(i-1) + '-' + col\n",
        "      tmp_df[col_2] = df[col_2] - df[col_1]\n",
        "\n",
        "  return tmp_df.drop(columns=['GAME_ID','TEAM_ID', 'WIN']).groupby(['PLAYER_ID']).sum().reset_index()\n",
        "\n",
        "def get_colapsed(season):\n",
        "  return df_by_season(all_season_ts, season).drop(columns=['season'])\n",
        "\n",
        "def get_players_embeddings(lle_space, season, reduce_to=25, n_neighbors=20):\n",
        "  '''\n",
        "  #df = df_by_season(players, season)\n",
        "\n",
        "  X = get_colapsed(season)#colapse_ts(get_players_ts(df))\n",
        "  embeddings = pd.DataFrame(lle_space.transform(X.drop(columns=['PLAYER_ID'])))\n",
        "  #embeddings = pd.DataFrame(lle_space.transform(X))\n",
        "  \n",
        "  return pd.concat([X['PLAYER_ID'].reset_index(drop=True), embeddings], axis=1)\n",
        "  #df = df_by_season(players, season)\n",
        "  #return df[['PLAYER_ID'] + ts_columns].groupby(['PLAYER_ID']).mean().reset_index()\n",
        "  '''\n",
        "  X = get_colapsed(season).reset_index(drop=True).drop(columns=['Unnamed: 0'])\n",
        "  #print(X)\n",
        "  player_embeddings = pd.concat([X['PLAYER_ID'], LLE(reduce_to, X.drop(columns=['PLAYER_ID']), n_neighbors=n_neighbors)], axis=1)\n",
        "  return player_embeddings\n",
        "  \n",
        "\n",
        "def comparison_dataframe(df, drop=['PLAYER_ID']):\n",
        "  mean_df = df.drop(columns=drop).groupby(['GAME_ID', 'TEAM_ID']).mean().reset_index()\n",
        "\n",
        "  mean_df = mean_df.merge(mean_df, how='inner', on='GAME_ID').sort_values(by=['GAME_ID', 'TEAM_ID_x'])\n",
        "  return mean_df.query('TEAM_ID_x != TEAM_ID_y') #.iloc[::2] \n",
        "\n",
        "def make_x_y(df):\n",
        "  X = df.drop(columns=['WIN_x', 'WIN_y', 'GAME_ID', 'TEAM_ID_x', 'TEAM_ID_y', 'season'])\n",
        "  y = df['WIN_x']\n",
        "  \n",
        "  return [X, y]\n",
        "\n",
        "\n",
        "def make_collection(full_comp_df, r=range(0, 5), reduce=None, conseq=False):\n",
        "  collection = []\n",
        "  for i in r: #len(seasons)-1):\n",
        "    arr = [seasons[i+2]]\n",
        "    train_season = seasons[i+1]\n",
        "    test_season = seasons[i+2]\n",
        "    \n",
        "    X_train, y_train = make_x_y(df_by_season(full_comp_df, train_season))\n",
        "    X_test, y_test = make_x_y(df_by_season(full_comp_df, test_season))\n",
        "\n",
        "    if conseq and collection:\n",
        "      _, prev_X_train, prev_y_train, _, _ = collection[-1]\n",
        "      X_train = pd.concat([prev_X_train, X_train])\n",
        "      y_train = pd.concat([prev_y_train, y_train])\n",
        "    \n",
        "    if reduce is not None:\n",
        "      red_obj = reduce(X_train)\n",
        "      X_train = red_obj.transform(X_train)\n",
        "      X_test = red_obj.transform(X_test)\n",
        "\n",
        "    print(len(X_train), len(X_test))\n",
        "    arr += [X_train, y_train]\n",
        "    arr += [X_test, y_test]\n",
        "    collection.append(tuple(arr))\n",
        "\n",
        "  return collection\n",
        "\n",
        "def max_accuracy(y_true, probs):\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_true, probs)\n",
        "  accuracy_scores = []\n",
        "  for thresh in thresholds:\n",
        "      accuracy_scores.append(metrics.accuracy_score(y_true, \n",
        "                                          [1 if m > thresh else 0 for m in probs]))\n",
        "\n",
        "  accuracies = np.array(accuracy_scores)\n",
        "  return accuracies.max() \n",
        "\n",
        "def max_tresh(y_true, probs):\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_true, probs)\n",
        "  accuracy_scores = []\n",
        "  for thresh in thresholds:\n",
        "      accuracy_scores.append((metrics.accuracy_score(y_true, \n",
        "                                          [1 if m > thresh else 0 for m in probs]), thresh))\n",
        "\n",
        "  #accuracies = np.array(accuracy_scores)\n",
        "  return max(accuracy_scores)[1] \n",
        "\n",
        "def plot_corr(df):\n",
        "  f = plt.figure(figsize=(30, 30))\n",
        "  plt.matshow(df.corr(), fignum=f.number)\n",
        "  plt.xticks(range(df.shape[1]), df.columns, fontsize=14, rotation=45)\n",
        "  plt.yticks(range(df.shape[1]), df.columns, fontsize=14)\n",
        "  cb = plt.colorbar()\n",
        "  cb.ax.tick_params(labelsize=14)\n",
        "  plt.title('Correlation Matrix', fontsize=16);\n",
        "\n",
        "def normalize_by(df, columns, by):\n",
        "  for col in columns:\n",
        "    df[col] /= df[by]\n",
        "\n",
        "  return df\n",
        "\n",
        "def remove_outliers(df, columns):\n",
        "  ch_df = df[columns]\n",
        "  return df[(np.abs(stats.zscore(ch_df)) < 3).all(axis=1)]\n",
        "\n",
        "\n",
        "def plr_df_from_file(file_name):\n",
        "  col_to_stat = ['FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'OREB', 'DREB', 'AST', 'TOV', 'STL', 'BLK', 'BLKA', 'PF', 'PFD']\n",
        "  df = pd.read_csv(file_name)\n",
        "  df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "  # Clean DATA\n",
        "  df.loc[df['MIN'] < 1, 'MIN'] = 1\n",
        "\n",
        "  df['WIN'] = 1*(df['WL'] == 'W')\n",
        "\n",
        "  #return df\n",
        "  return normalize_by(df, ['FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'OREB', 'DREB', 'AST', 'TOV', 'STL', 'BLK', 'BLKA', 'PF', 'PFD'], by='MIN')\n",
        "\n",
        "\n",
        "df = plr_df_from_file('drive/My Drive/SL Project/player_games_with_inactive_score.csv')\n",
        "players = plr_df_from_file('drive/My Drive/SL Project/players_with_inactive_score-2012-2019.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIZ2nMWXhhxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRDt-_bYyqBo",
        "colab_type": "text"
      },
      "source": [
        "# Kernel PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8lkcOMGysib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kernel_pca(n_comp, X, kernel='rbf'):\n",
        "  kpca = KernelPCA(n_comp, kernel=kernel)\n",
        "  X_kpca = kpca.fit_transform(X)\n",
        "\n",
        "  kpca_df = pd.DataFrame(X_kpca)\n",
        "  return kpca_df\n",
        "\n",
        "def LLE(n_comp, X, method='standard', n_neighbors=5):\n",
        "  if method == 'modified':\n",
        "    n_neighbors = n_comp + 1\n",
        "  elif method=='hessian':\n",
        "    n_neighbors = int(n_comp * (n_comp + 3) / 2) + 2\n",
        "  else:\n",
        "    n_neighbors = n_neighbors\n",
        "\n",
        "  embedding = LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=n_comp, method = method)\n",
        "  return pd.DataFrame(embedding.fit_transform(X))\n",
        "\n",
        "def SE(n_comp, X):\n",
        "  embedding = SpectralEmbedding(n_components=n_comp)\n",
        "  return pd.DataFrame(embedding.fit_transform(X))\n",
        "\n",
        "def pca(n_comp, X):\n",
        "  pca = PCA(n_components=n_comp)\n",
        "  return pd.DataFrame(pca.fit_transform(X))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIsIHI-sholx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBAjar4k5jCa",
        "colab_type": "text"
      },
      "source": [
        "# Blocked cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAA2qBgC5lwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BlockingTimeSeriesSplit():\n",
        "    def __init__(self, n_splits):\n",
        "        self.n_splits = n_splits\n",
        "    \n",
        "    def get_n_splits(self, X, y, groups):\n",
        "        return self.n_splits\n",
        "    \n",
        "    def split(self, X, y=None, groups=None):\n",
        "        n_samples = len(X)\n",
        "        k_fold_size = n_samples // self.n_splits\n",
        "        indices = np.arange(n_samples)\n",
        "\n",
        "        margin = 0\n",
        "        for i in range(self.n_splits):\n",
        "            start = i * k_fold_size\n",
        "            stop = start + k_fold_size\n",
        "            mid = int(0.8 * (stop - start)) + start\n",
        "            yield indices[start: mid], indices[mid + margin: stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmeexvRkzUdi",
        "colab_type": "text"
      },
      "source": [
        "# Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DswT2lE8zWTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "def plot_feature_importances(df_fi, num_limit = None):\n",
        "    ''' Plot feature importances barplot'''\n",
        "    if not num_limit:\n",
        "        num_limit = df_fi.shape[0]\n",
        "        \n",
        "    f, ax = plt.subplots(figsize=(12, num_limit / 2))\n",
        "    \n",
        "    sns.set(style=\"whitegrid\")\n",
        "    sns.set_color_codes(\"pastel\")\n",
        "    sns.barplot( x=\"importance\", y=\"feature\", \n",
        "                data=df_fi[:num_limit], color=\"b\"\n",
        "               ).set_title('Feature importance')\n",
        "    \n",
        "    return df_fi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9N1WIPMh4Jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXwoFAln0Drm",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOZA1eQu0HrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import threading\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "class ParaForest:\n",
        "  seed = 0\n",
        "  num_threads = 5\n",
        "  \n",
        "  def __init__(self, X=None, y=None, params=None, fit_instantly=True):\n",
        "    self.params = params\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "    self.regressors = []\n",
        "    self.forests  = []\n",
        "\n",
        "    if fit_instantly:\n",
        "      self.run_thread()\n",
        "\n",
        "  def run_thread(self):\n",
        "    threads = []\n",
        "    for i in range(self.num_threads):\n",
        "      threads.append( threading.Thread(target=self.__thread, args=(self.seed + i,)))\n",
        "      threads[-1].start()\n",
        "\n",
        "    for i in range(self.num_threads):\n",
        "      threads[i].join()\n",
        "\n",
        "    self.regressors[0].estimators_ = self.forests\n",
        "    self.model = self.regressors[0]\n",
        "\n",
        "  def __thread(self, seed):\n",
        "    regr = RandomForestClassifier(**self.params, random_state=seed)\n",
        "    regr.fit(self.X, self.y)\n",
        "    self.regressors.append(regr)\n",
        "    self.forests += regr.estimators_\n",
        "    #print('Finished: ', seed)\n",
        "    \n",
        "  def fit(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.run_thread()\n",
        "    return self\n",
        "\n",
        "  def predict(self, x):\n",
        "    return self.model.predict(x)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0cuc1zLiAJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4kfomToiAUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWuu9GPhiAXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM3iTSsCrcGR",
        "colab_type": "text"
      },
      "source": [
        "# Simple avarage features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITKpJ7uTfNTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4adbd730-50ca-4dea-a83a-f22c34ed6a21"
      },
      "source": [
        "sa_ts_num = 60\n",
        "\n",
        "def ts_for_avareging(sa_ts_num):\n",
        "  ts_columns = ['MIN','FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'OREB', 'DREB', 'AST', 'TOV', 'STL', 'BLK', 'BLKA', 'PF', 'PFD']\n",
        "\n",
        "  plr_df = make_ts(players.sort_values(by=['PLAYER_ID', 'GAME_ID']), \n",
        "          id_column='PLAYER_ID', \n",
        "          columns_for_ts=ts_columns,\n",
        "          columns_to_keep=['TEAM_ID', 'GAME_ID', 'WIN', 'season'], \n",
        "          num_of_shifts=sa_ts_num,\n",
        "          if_nan=0)\n",
        "\n",
        "  plr_back_ts = plr_df.dropna()\n",
        "  return plr_back_ts\n",
        "\n",
        "plr_back_ts = ts_for_avareging(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Oc4bsErf2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def full_comp_for_avareging(plr_back_ts, ts_num, comparison=True):\n",
        "  full_comp_df = plr_back_ts.loc[:, ['GAME_ID', 'TEAM_ID', 'PLAYER_ID', 'WIN']]\n",
        "  season_df = plr_back_ts.loc[:, ['GAME_ID', 'season']].drop_duplicates()\n",
        "\n",
        "  for col in ts_columns:\n",
        "    full_comp_df.loc[:, col] = 0\n",
        "    for i in range(1, ts_num+1):\n",
        "      full_comp_df.loc[:, col] += plr_back_ts[str(i) + '-' + col] / ts_num\n",
        "\n",
        "  if comparison:\n",
        "    return comparison_dataframe(full_comp_df).merge(season_df, how='left', on='GAME_ID')\n",
        "  return full_comp_df\n",
        "\n",
        "full_comp_df = full_comp_for_avareging(plr_back_ts, 3, comparison=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kxqJoHBC5_m",
        "colab_type": "text"
      },
      "source": [
        "## Make collection fuction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz_2XdLI29dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seasons = ['20'+str(i-1)+'-'+str(i) for i in range(13,20)]\n",
        "\n",
        "def make_collection(full_comp_df, r=range(0, 5), reduce=None, conseq=False):\n",
        "  collection = []\n",
        "  for i in r: #len(seasons)-1):\n",
        "    arr = [seasons[i+2]]\n",
        "    train_season = seasons[i+1]\n",
        "    test_season = seasons[i+2]\n",
        "    \n",
        "    X_train, y_train = make_x_y(df_by_season(full_comp_df, train_season))\n",
        "    X_test, y_test = make_x_y(df_by_season(full_comp_df, test_season))\n",
        "\n",
        "    if conseq and collection:\n",
        "      _, prev_X_train, prev_y_train, _, _ = collection[-1]\n",
        "      X_train = pd.concat([prev_X_train, X_train])\n",
        "      y_train = pd.concat([prev_y_train, y_train])\n",
        "    \n",
        "    if reduce is not None:\n",
        "      red_obj = reduce(X_train)\n",
        "      X_train = red_obj.transform(X_train)\n",
        "      X_test = red_obj.transform(X_test)\n",
        "\n",
        "    print(len(X_train), len(X_test))\n",
        "    arr += [X_train, y_train]\n",
        "    arr += [X_test, y_test]\n",
        "    collection.append(tuple(arr))\n",
        "\n",
        "  return collection\n",
        "  \n",
        "\n",
        "#collection = make_collection(full_comp_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1BIoOEOnvyA",
        "colab_type": "text"
      },
      "source": [
        "## Optimal ts size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAnsVTKPneWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "baaf4729-fe8b-430a-9eb5-2ccc9ebeefa9"
      },
      "source": [
        "res = []\n",
        "for ts_size in [10,20, 30, 40, 50, 60, 70]:\n",
        "  plr_back_ts = ts_for_avareging(ts_size)\n",
        "  full_comp_df = full_comp_for_avareging(plr_back_ts, ts_size)\n",
        "  \n",
        "  collection = make_collection(full_comp_df, range(0,4))\n",
        "  pf_res, cols, preds, av_accuracy = mul_train(collection)\n",
        "  \n",
        "  res.append((ts_size, av_accuracy))\n",
        "\n",
        "\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2013-14 0.6036585365853658\n",
            "2014-15 0.5804878048780487\n",
            "2015-16 0.574390243902439\n",
            "2016-17 0.5768292682926829\n",
            "Avarage:  0.583841463414634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2013-14 0.6182926829268293\n",
            "2014-15 0.6109756097560975\n",
            "2015-16 0.5979674796747968\n",
            "2016-17 0.5817073170731707\n",
            "Avarage:  0.6022357723577235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2013-14 0.6308943089430894\n",
            "2014-15 0.6207317073170732\n",
            "2015-16 0.5857723577235773\n",
            "2016-17 0.5991869918699188\n",
            "Avarage:  0.6091463414634146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2013-14 0.6369918699186992\n",
            "2014-15 0.6292682926829268\n",
            "2015-16 0.5991869918699188\n",
            "2016-17 0.6016260162601627\n",
            "Avarage:  0.6167682926829268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2013-14 0.6447154471544716\n",
            "2014-15 0.6292682926829268\n",
            "2015-16 0.5910569105691057\n",
            "2016-17 0.6085365853658536\n",
            "Avarage:  0.6183943089430894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2013-14 0.6483739837398373\n",
            "2014-15 0.6264227642276423\n",
            "2015-16 0.5951219512195122\n",
            "2016-17 0.6142276422764228\n",
            "Avarage:  0.6210365853658537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2013-14 0.6455284552845528\n",
            "2014-15 0.6235772357723577\n",
            "2015-16 0.5898373983739837\n",
            "2016-17 0.6231707317073171\n",
            "Avarage:  0.6205284552845528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(10, 0.583841463414634),\n",
              " (20, 0.6022357723577235),\n",
              " (30, 0.6091463414634146),\n",
              " (40, 0.6167682926829268),\n",
              " (50, 0.6183943089430894),\n",
              " (60, 0.6210365853658537),\n",
              " (70, 0.6205284552845528)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FJ9utRQrPzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "94f0c20e-686c-415c-f32a-8cc8bf987a9a"
      },
      "source": [
        "res = [(10, 0.583841463414634),\n",
        " (20, 0.6022357723577235),\n",
        " (30, 0.6091463414634146),\n",
        " (40, 0.6167682926829268),\n",
        " (50, 0.6183943089430894),\n",
        " (60, 0.6210365853658537),\n",
        " (70, 0.6205284552845528)]\n",
        "opt_size = np.array(res)\n",
        "plt.plot(opt_size[:,0], opt_size[:,1])\n",
        "plt.xlabel('N games before')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGlIXc3vkC7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GM3MOj9wAYl",
        "colab_type": "text"
      },
      "source": [
        "# K-MEANS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aSF4pFrxmtX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "6e463852-8764-480e-b7bb-6e541b16e4b1"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "sys_cols = ['GAME_ID', 'TEAM_ID', 'WIN', 'season', 'PLAYER_ID']\n",
        "df_for_clust = df_by_season(plr_back_ts, '2013-14').drop(columns=sys_cols)\n",
        "df_for_clust"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MIN_OK</th>\n",
              "      <th>1-MIN</th>\n",
              "      <th>2-MIN</th>\n",
              "      <th>3-MIN</th>\n",
              "      <th>FGM_OK</th>\n",
              "      <th>1-FGM</th>\n",
              "      <th>2-FGM</th>\n",
              "      <th>3-FGM</th>\n",
              "      <th>FGA_OK</th>\n",
              "      <th>1-FGA</th>\n",
              "      <th>2-FGA</th>\n",
              "      <th>3-FGA</th>\n",
              "      <th>FG_PCT_OK</th>\n",
              "      <th>1-FG_PCT</th>\n",
              "      <th>2-FG_PCT</th>\n",
              "      <th>3-FG_PCT</th>\n",
              "      <th>FG3M_OK</th>\n",
              "      <th>1-FG3M</th>\n",
              "      <th>2-FG3M</th>\n",
              "      <th>3-FG3M</th>\n",
              "      <th>FG3A_OK</th>\n",
              "      <th>1-FG3A</th>\n",
              "      <th>2-FG3A</th>\n",
              "      <th>3-FG3A</th>\n",
              "      <th>FG3_PCT_OK</th>\n",
              "      <th>1-FG3_PCT</th>\n",
              "      <th>2-FG3_PCT</th>\n",
              "      <th>3-FG3_PCT</th>\n",
              "      <th>OREB_OK</th>\n",
              "      <th>1-OREB</th>\n",
              "      <th>2-OREB</th>\n",
              "      <th>3-OREB</th>\n",
              "      <th>DREB_OK</th>\n",
              "      <th>1-DREB</th>\n",
              "      <th>2-DREB</th>\n",
              "      <th>3-DREB</th>\n",
              "      <th>AST_OK</th>\n",
              "      <th>1-AST</th>\n",
              "      <th>2-AST</th>\n",
              "      <th>3-AST</th>\n",
              "      <th>TOV_OK</th>\n",
              "      <th>1-TOV</th>\n",
              "      <th>2-TOV</th>\n",
              "      <th>3-TOV</th>\n",
              "      <th>STL_OK</th>\n",
              "      <th>1-STL</th>\n",
              "      <th>2-STL</th>\n",
              "      <th>3-STL</th>\n",
              "      <th>BLK_OK</th>\n",
              "      <th>1-BLK</th>\n",
              "      <th>2-BLK</th>\n",
              "      <th>3-BLK</th>\n",
              "      <th>BLKA_OK</th>\n",
              "      <th>1-BLKA</th>\n",
              "      <th>2-BLKA</th>\n",
              "      <th>3-BLKA</th>\n",
              "      <th>PF_OK</th>\n",
              "      <th>1-PF</th>\n",
              "      <th>2-PF</th>\n",
              "      <th>3-PF</th>\n",
              "      <th>PFD_OK</th>\n",
              "      <th>1-PFD</th>\n",
              "      <th>2-PFD</th>\n",
              "      <th>3-PFD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>1</td>\n",
              "      <td>18.600000</td>\n",
              "      <td>27.580000</td>\n",
              "      <td>23.988333</td>\n",
              "      <td>1</td>\n",
              "      <td>0.376344</td>\n",
              "      <td>0.181291</td>\n",
              "      <td>0.250122</td>\n",
              "      <td>1</td>\n",
              "      <td>0.430108</td>\n",
              "      <td>0.398840</td>\n",
              "      <td>0.375182</td>\n",
              "      <td>1</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.667</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.072516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.483871</td>\n",
              "      <td>0.217549</td>\n",
              "      <td>0.250122</td>\n",
              "      <td>1</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.145033</td>\n",
              "      <td>0.125061</td>\n",
              "      <td>1</td>\n",
              "      <td>0.053763</td>\n",
              "      <td>0.108774</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.053763</td>\n",
              "      <td>0.036258</td>\n",
              "      <td>0.083374</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041687</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.053763</td>\n",
              "      <td>0.036258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.072516</td>\n",
              "      <td>0.041687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>1</td>\n",
              "      <td>26.280000</td>\n",
              "      <td>18.600000</td>\n",
              "      <td>27.580000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.152207</td>\n",
              "      <td>0.376344</td>\n",
              "      <td>0.181291</td>\n",
              "      <td>1</td>\n",
              "      <td>0.304414</td>\n",
              "      <td>0.430108</td>\n",
              "      <td>0.398840</td>\n",
              "      <td>1</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.455</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.076104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.072516</td>\n",
              "      <td>1</td>\n",
              "      <td>0.304414</td>\n",
              "      <td>0.483871</td>\n",
              "      <td>0.217549</td>\n",
              "      <td>1</td>\n",
              "      <td>0.114155</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.145033</td>\n",
              "      <td>1</td>\n",
              "      <td>0.076104</td>\n",
              "      <td>0.053763</td>\n",
              "      <td>0.108774</td>\n",
              "      <td>1</td>\n",
              "      <td>0.076104</td>\n",
              "      <td>0.053763</td>\n",
              "      <td>0.036258</td>\n",
              "      <td>1</td>\n",
              "      <td>0.038052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.152207</td>\n",
              "      <td>0.053763</td>\n",
              "      <td>0.036258</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.072516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>1</td>\n",
              "      <td>25.800000</td>\n",
              "      <td>26.280000</td>\n",
              "      <td>18.600000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.152207</td>\n",
              "      <td>0.376344</td>\n",
              "      <td>1</td>\n",
              "      <td>0.426357</td>\n",
              "      <td>0.304414</td>\n",
              "      <td>0.430108</td>\n",
              "      <td>1</td>\n",
              "      <td>0.273</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.875</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.038760</td>\n",
              "      <td>0.076104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>0.304414</td>\n",
              "      <td>0.483871</td>\n",
              "      <td>1</td>\n",
              "      <td>0.077519</td>\n",
              "      <td>0.114155</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>1</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.076104</td>\n",
              "      <td>0.053763</td>\n",
              "      <td>1</td>\n",
              "      <td>0.038760</td>\n",
              "      <td>0.076104</td>\n",
              "      <td>0.053763</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.152207</td>\n",
              "      <td>0.053763</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>1</td>\n",
              "      <td>22.416667</td>\n",
              "      <td>25.800000</td>\n",
              "      <td>26.280000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.133829</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.152207</td>\n",
              "      <td>1</td>\n",
              "      <td>0.490706</td>\n",
              "      <td>0.426357</td>\n",
              "      <td>0.304414</td>\n",
              "      <td>1</td>\n",
              "      <td>0.273</td>\n",
              "      <td>0.273</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.044610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038760</td>\n",
              "      <td>0.076104</td>\n",
              "      <td>1</td>\n",
              "      <td>0.223048</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>0.304414</td>\n",
              "      <td>1</td>\n",
              "      <td>0.044610</td>\n",
              "      <td>0.077519</td>\n",
              "      <td>0.114155</td>\n",
              "      <td>1</td>\n",
              "      <td>0.044610</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.076104</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038760</td>\n",
              "      <td>0.076104</td>\n",
              "      <td>1</td>\n",
              "      <td>0.044610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038052</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.089219</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.152207</td>\n",
              "      <td>1</td>\n",
              "      <td>0.178439</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>1</td>\n",
              "      <td>13.600000</td>\n",
              "      <td>22.416667</td>\n",
              "      <td>25.800000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.147059</td>\n",
              "      <td>0.133829</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>1</td>\n",
              "      <td>0.367647</td>\n",
              "      <td>0.490706</td>\n",
              "      <td>0.426357</td>\n",
              "      <td>1</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.273</td>\n",
              "      <td>0.273</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038760</td>\n",
              "      <td>1</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.223048</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073529</td>\n",
              "      <td>0.044610</td>\n",
              "      <td>0.077519</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073529</td>\n",
              "      <td>0.044610</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038760</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073529</td>\n",
              "      <td>0.089219</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073529</td>\n",
              "      <td>0.178439</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141421</th>\n",
              "      <td>1</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>7.166667</td>\n",
              "      <td>14.200000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>0.352113</td>\n",
              "      <td>1</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>0.281690</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070423</td>\n",
              "      <td>1</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070423</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140845</td>\n",
              "      <td>1</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141422</th>\n",
              "      <td>1</td>\n",
              "      <td>11.416667</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>7.166667</td>\n",
              "      <td>1</td>\n",
              "      <td>0.262774</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>1</td>\n",
              "      <td>0.350365</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>1</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1</td>\n",
              "      <td>0.087591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>1</td>\n",
              "      <td>0.175182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.175182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.087591</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.175182</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141423</th>\n",
              "      <td>1</td>\n",
              "      <td>13.683333</td>\n",
              "      <td>11.416667</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.292326</td>\n",
              "      <td>0.262774</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>1</td>\n",
              "      <td>0.438490</td>\n",
              "      <td>0.350365</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1</td>\n",
              "      <td>0.667</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073082</td>\n",
              "      <td>0.087591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.146163</td>\n",
              "      <td>0.175182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073082</td>\n",
              "      <td>0.175182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.087591</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073082</td>\n",
              "      <td>0.175182</td>\n",
              "      <td>0.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141424</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141425</th>\n",
              "      <td>0</td>\n",
              "      <td>1.816667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.550459</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.550459</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25618 rows × 64 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        MIN_OK      1-MIN      2-MIN  ...     1-PFD     2-PFD     3-PFD\n",
              "219          1  18.600000  27.580000  ...  0.000000  0.072516  0.041687\n",
              "220          1  26.280000  18.600000  ...  0.000000  0.000000  0.072516\n",
              "221          1  25.800000  26.280000  ...  0.000000  0.000000  0.000000\n",
              "222          1  22.416667  25.800000  ...  0.178439  0.000000  0.000000\n",
              "223          1  13.600000  22.416667  ...  0.073529  0.178439  0.000000\n",
              "...        ...        ...        ...  ...       ...       ...       ...\n",
              "141421       1   5.500000   7.166667  ...  0.181818  0.000000  0.000000\n",
              "141422       1  11.416667   5.500000  ...  0.175182  0.181818  0.000000\n",
              "141423       1  13.683333  11.416667  ...  0.073082  0.175182  0.181818\n",
              "141424       0   0.000000   0.000000  ...  0.000000  0.000000  0.000000\n",
              "141425       0   1.816667   0.000000  ...  0.550459  0.000000  0.000000\n",
              "\n",
              "[25618 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In0IT7Y-1isv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for k in range(5,6):\n",
        "  print(k)\n",
        "  kmeanModel = KMeans(n_clusters=5)\n",
        "  kmeanModel.fit(df_for_clust)\n",
        "  kmeans_df = pd.concat([plr_back_ts[sys_cols], pd.DataFrame(kmeanModel.transform(plr_back_ts.drop(columns=sys_cols)))], axis=1)\n",
        "  season_df = plr_back_ts[['GAME_ID', 'season']]\n",
        "  full_comp_df = comparison_dataframe(kmeans_df).merge(season_df.drop_duplicates(), how='left', on='GAME_ID')\n",
        "  collection = make_collection(full_comp_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn98LLLuHQaa",
        "colab_type": "text"
      },
      "source": [
        "# TS Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJQ0efISHTFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "eee49b39-14d2-4698-9972-5b3aab1b960d"
      },
      "source": [
        "def ts_stat(ts_df, columns, stat_func):\n",
        "  res_df = pd.DataFrame()\n",
        "  for col in columns:\n",
        "    res_df[col] = stat_func(ts_df[[str(i) + '-' + col for i in range(1, ts_num+1)]].values)\n",
        "  return res_df\n",
        "\n",
        "def slope(y):\n",
        "  res = []\n",
        "  x = list(range(len(y[0])))\n",
        "  for i in range(len(y)):\n",
        "    res.append(np.polyfit(x, y[i], 1)[0])\n",
        "  \n",
        "  return res\n",
        "\n",
        "plr_ts = plr_back_ts.reset_index()\n",
        "\n",
        "ts_stat_df = pd.concat([ plr_ts[['GAME_ID', 'TEAM_ID', 'PLAYER_ID', 'WIN']],\n",
        "           ts_stat(plr_ts, ts_columns, lambda x: np.mean(x, axis=1)).add_prefix('mean-'),\n",
        "           ts_stat(plr_ts, ts_columns, lambda x: np.median(x, axis=1)).add_prefix('median-'),\n",
        "           ts_stat(plr_ts, ts_columns, lambda x: np.std(x, axis=1)).add_prefix('std-'),\n",
        "           ts_stat(plr_ts, ts_columns, lambda x: np.min(x, axis=1)).add_prefix('min-'),\n",
        "           ts_stat(plr_ts, ts_columns, lambda x: np.max(x, axis=1)).add_prefix('max-'),\n",
        "           ts_stat(plr_ts, ts_columns, lambda x: skew(x, axis=1)).add_prefix('skew-'),\n",
        "\n",
        "           ts_stat(plr_ts, ts_columns, lambda x: slope(x)).add_prefix('slope-')], axis=1)\n",
        "\n",
        "ts_stat_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GAME_ID</th>\n",
              "      <th>TEAM_ID</th>\n",
              "      <th>PLAYER_ID</th>\n",
              "      <th>WIN</th>\n",
              "      <th>mean-MIN</th>\n",
              "      <th>mean-FGM</th>\n",
              "      <th>mean-FGA</th>\n",
              "      <th>mean-FG_PCT</th>\n",
              "      <th>mean-FG3M</th>\n",
              "      <th>mean-FG3A</th>\n",
              "      <th>mean-FG3_PCT</th>\n",
              "      <th>mean-OREB</th>\n",
              "      <th>mean-DREB</th>\n",
              "      <th>mean-AST</th>\n",
              "      <th>mean-TOV</th>\n",
              "      <th>mean-STL</th>\n",
              "      <th>mean-BLK</th>\n",
              "      <th>mean-BLKA</th>\n",
              "      <th>mean-PF</th>\n",
              "      <th>mean-PFD</th>\n",
              "      <th>median-MIN</th>\n",
              "      <th>median-FGM</th>\n",
              "      <th>median-FGA</th>\n",
              "      <th>median-FG_PCT</th>\n",
              "      <th>median-FG3M</th>\n",
              "      <th>median-FG3A</th>\n",
              "      <th>median-FG3_PCT</th>\n",
              "      <th>median-OREB</th>\n",
              "      <th>median-DREB</th>\n",
              "      <th>median-AST</th>\n",
              "      <th>median-TOV</th>\n",
              "      <th>median-STL</th>\n",
              "      <th>median-BLK</th>\n",
              "      <th>median-BLKA</th>\n",
              "      <th>median-PF</th>\n",
              "      <th>median-PFD</th>\n",
              "      <th>std-MIN</th>\n",
              "      <th>std-FGM</th>\n",
              "      <th>std-FGA</th>\n",
              "      <th>std-FG_PCT</th>\n",
              "      <th>...</th>\n",
              "      <th>max-DREB</th>\n",
              "      <th>max-AST</th>\n",
              "      <th>max-TOV</th>\n",
              "      <th>max-STL</th>\n",
              "      <th>max-BLK</th>\n",
              "      <th>max-BLKA</th>\n",
              "      <th>max-PF</th>\n",
              "      <th>max-PFD</th>\n",
              "      <th>skew-MIN</th>\n",
              "      <th>skew-FGM</th>\n",
              "      <th>skew-FGA</th>\n",
              "      <th>skew-FG_PCT</th>\n",
              "      <th>skew-FG3M</th>\n",
              "      <th>skew-FG3A</th>\n",
              "      <th>skew-FG3_PCT</th>\n",
              "      <th>skew-OREB</th>\n",
              "      <th>skew-DREB</th>\n",
              "      <th>skew-AST</th>\n",
              "      <th>skew-TOV</th>\n",
              "      <th>skew-STL</th>\n",
              "      <th>skew-BLK</th>\n",
              "      <th>skew-BLKA</th>\n",
              "      <th>skew-PF</th>\n",
              "      <th>skew-PFD</th>\n",
              "      <th>slope-MIN</th>\n",
              "      <th>slope-FGM</th>\n",
              "      <th>slope-FGA</th>\n",
              "      <th>slope-FG_PCT</th>\n",
              "      <th>slope-FG3M</th>\n",
              "      <th>slope-FG3A</th>\n",
              "      <th>slope-FG3_PCT</th>\n",
              "      <th>slope-OREB</th>\n",
              "      <th>slope-DREB</th>\n",
              "      <th>slope-AST</th>\n",
              "      <th>slope-TOV</th>\n",
              "      <th>slope-STL</th>\n",
              "      <th>slope-BLK</th>\n",
              "      <th>slope-BLKA</th>\n",
              "      <th>slope-PF</th>\n",
              "      <th>slope-PFD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21200541</td>\n",
              "      <td>1610612746</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21200559</td>\n",
              "      <td>1610612746</td>\n",
              "      <td>255</td>\n",
              "      <td>1</td>\n",
              "      <td>0.320833</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023377</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015584</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007792</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.398480</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.101896</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.311688</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.155844</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>-0.091667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.006679</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.004453</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.002226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21200567</td>\n",
              "      <td>1610612746</td>\n",
              "      <td>255</td>\n",
              "      <td>1</td>\n",
              "      <td>1.180833</td>\n",
              "      <td>0.008721</td>\n",
              "      <td>0.037912</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002907</td>\n",
              "      <td>0.024305</td>\n",
              "      <td>0.011628</td>\n",
              "      <td>0.002907</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002907</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005814</td>\n",
              "      <td>0.010699</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.931452</td>\n",
              "      <td>0.038014</td>\n",
              "      <td>0.117121</td>\n",
              "      <td>0.130767</td>\n",
              "      <td>...</td>\n",
              "      <td>0.311688</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>0.058140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05814</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.155844</td>\n",
              "      <td>3.476165</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>2.940071</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>3.049894</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>3.476165</td>\n",
              "      <td>-0.327732</td>\n",
              "      <td>-0.002492</td>\n",
              "      <td>-0.010129</td>\n",
              "      <td>-0.008571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000831</td>\n",
              "      <td>-0.006476</td>\n",
              "      <td>-0.003322</td>\n",
              "      <td>-0.000831</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000831</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.001661</td>\n",
              "      <td>-0.002823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21200581</td>\n",
              "      <td>1610612746</td>\n",
              "      <td>255</td>\n",
              "      <td>1</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.011773</td>\n",
              "      <td>0.044015</td>\n",
              "      <td>0.055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002907</td>\n",
              "      <td>0.024305</td>\n",
              "      <td>0.017732</td>\n",
              "      <td>0.009011</td>\n",
              "      <td>0.003052</td>\n",
              "      <td>0.002907</td>\n",
              "      <td>0.003052</td>\n",
              "      <td>0.021073</td>\n",
              "      <td>0.019855</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.125560</td>\n",
              "      <td>0.039608</td>\n",
              "      <td>0.118162</td>\n",
              "      <td>0.165756</td>\n",
              "      <td>...</td>\n",
              "      <td>0.311688</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>0.122075</td>\n",
              "      <td>0.061038</td>\n",
              "      <td>0.05814</td>\n",
              "      <td>0.061038</td>\n",
              "      <td>0.305188</td>\n",
              "      <td>0.183113</td>\n",
              "      <td>2.390394</td>\n",
              "      <td>3.534829</td>\n",
              "      <td>2.727623</td>\n",
              "      <td>2.711872</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>3.049894</td>\n",
              "      <td>3.119290</td>\n",
              "      <td>3.225547</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>3.456091</td>\n",
              "      <td>2.466495</td>\n",
              "      <td>-0.526266</td>\n",
              "      <td>-0.003101</td>\n",
              "      <td>-0.010733</td>\n",
              "      <td>-0.014812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000743</td>\n",
              "      <td>-0.005745</td>\n",
              "      <td>-0.004716</td>\n",
              "      <td>-0.002487</td>\n",
              "      <td>-0.000872</td>\n",
              "      <td>-0.000743</td>\n",
              "      <td>-0.000872</td>\n",
              "      <td>-0.005846</td>\n",
              "      <td>-0.005117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21200600</td>\n",
              "      <td>1610612746</td>\n",
              "      <td>255</td>\n",
              "      <td>1</td>\n",
              "      <td>2.925833</td>\n",
              "      <td>0.011773</td>\n",
              "      <td>0.046716</td>\n",
              "      <td>0.055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002907</td>\n",
              "      <td>0.027006</td>\n",
              "      <td>0.020432</td>\n",
              "      <td>0.009011</td>\n",
              "      <td>0.003052</td>\n",
              "      <td>0.002907</td>\n",
              "      <td>0.003052</td>\n",
              "      <td>0.026474</td>\n",
              "      <td>0.019855</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.233314</td>\n",
              "      <td>0.039608</td>\n",
              "      <td>0.117742</td>\n",
              "      <td>0.165756</td>\n",
              "      <td>...</td>\n",
              "      <td>0.311688</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>0.122075</td>\n",
              "      <td>0.061038</td>\n",
              "      <td>0.05814</td>\n",
              "      <td>0.061038</td>\n",
              "      <td>0.305188</td>\n",
              "      <td>0.183113</td>\n",
              "      <td>1.812028</td>\n",
              "      <td>3.534829</td>\n",
              "      <td>2.690772</td>\n",
              "      <td>2.711872</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>2.942291</td>\n",
              "      <td>2.927578</td>\n",
              "      <td>3.225547</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>4.129483</td>\n",
              "      <td>3.000361</td>\n",
              "      <td>2.466495</td>\n",
              "      <td>-0.730639</td>\n",
              "      <td>-0.002747</td>\n",
              "      <td>-0.010180</td>\n",
              "      <td>-0.013158</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000656</td>\n",
              "      <td>-0.005785</td>\n",
              "      <td>-0.004955</td>\n",
              "      <td>-0.002216</td>\n",
              "      <td>-0.000780</td>\n",
              "      <td>-0.000656</td>\n",
              "      <td>-0.000780</td>\n",
              "      <td>-0.006755</td>\n",
              "      <td>-0.004520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 116 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    GAME_ID     TEAM_ID  PLAYER_ID  ...  slope-BLKA  slope-PF  slope-PFD\n",
              "0  21200541  1610612746        255  ...    0.000000  0.000000   0.000000\n",
              "1  21200559  1610612746        255  ...    0.000000  0.000000  -0.002226\n",
              "2  21200567  1610612746        255  ...    0.000000 -0.001661  -0.002823\n",
              "3  21200581  1610612746        255  ...   -0.000872 -0.005846  -0.005117\n",
              "4  21200600  1610612746        255  ...   -0.000780 -0.006755  -0.004520\n",
              "\n",
              "[5 rows x 116 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djZe9GvWLFa-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "f3cb3f92-1f96-411d-98c9-da8d6b770e51"
      },
      "source": [
        "df_to_compare = ts_stat_df\n",
        "season_df = plr_ts[['GAME_ID', 'season']]\n",
        "full_comp_df = comparison_dataframe(df_to_compare).merge(season_df.drop_duplicates(), how='left', on='GAME_ID').sort_values(['GAME_ID', 'TEAM_ID_x'])\n",
        "full_comp_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GAME_ID</th>\n",
              "      <th>TEAM_ID_x</th>\n",
              "      <th>WIN_x</th>\n",
              "      <th>mean-MIN_x</th>\n",
              "      <th>mean-FGM_x</th>\n",
              "      <th>mean-FGA_x</th>\n",
              "      <th>mean-FG_PCT_x</th>\n",
              "      <th>mean-FG3M_x</th>\n",
              "      <th>mean-FG3A_x</th>\n",
              "      <th>mean-FG3_PCT_x</th>\n",
              "      <th>mean-OREB_x</th>\n",
              "      <th>mean-DREB_x</th>\n",
              "      <th>mean-AST_x</th>\n",
              "      <th>mean-TOV_x</th>\n",
              "      <th>mean-STL_x</th>\n",
              "      <th>mean-BLK_x</th>\n",
              "      <th>mean-BLKA_x</th>\n",
              "      <th>mean-PF_x</th>\n",
              "      <th>mean-PFD_x</th>\n",
              "      <th>median-MIN_x</th>\n",
              "      <th>median-FGM_x</th>\n",
              "      <th>median-FGA_x</th>\n",
              "      <th>median-FG_PCT_x</th>\n",
              "      <th>median-FG3M_x</th>\n",
              "      <th>median-FG3A_x</th>\n",
              "      <th>median-FG3_PCT_x</th>\n",
              "      <th>median-OREB_x</th>\n",
              "      <th>median-DREB_x</th>\n",
              "      <th>median-AST_x</th>\n",
              "      <th>median-TOV_x</th>\n",
              "      <th>median-STL_x</th>\n",
              "      <th>median-BLK_x</th>\n",
              "      <th>median-BLKA_x</th>\n",
              "      <th>median-PF_x</th>\n",
              "      <th>median-PFD_x</th>\n",
              "      <th>std-MIN_x</th>\n",
              "      <th>std-FGM_x</th>\n",
              "      <th>std-FGA_x</th>\n",
              "      <th>std-FG_PCT_x</th>\n",
              "      <th>std-FG3M_x</th>\n",
              "      <th>...</th>\n",
              "      <th>max-AST_y</th>\n",
              "      <th>max-TOV_y</th>\n",
              "      <th>max-STL_y</th>\n",
              "      <th>max-BLK_y</th>\n",
              "      <th>max-BLKA_y</th>\n",
              "      <th>max-PF_y</th>\n",
              "      <th>max-PFD_y</th>\n",
              "      <th>skew-MIN_y</th>\n",
              "      <th>skew-FGM_y</th>\n",
              "      <th>skew-FGA_y</th>\n",
              "      <th>skew-FG_PCT_y</th>\n",
              "      <th>skew-FG3M_y</th>\n",
              "      <th>skew-FG3A_y</th>\n",
              "      <th>skew-FG3_PCT_y</th>\n",
              "      <th>skew-OREB_y</th>\n",
              "      <th>skew-DREB_y</th>\n",
              "      <th>skew-AST_y</th>\n",
              "      <th>skew-TOV_y</th>\n",
              "      <th>skew-STL_y</th>\n",
              "      <th>skew-BLK_y</th>\n",
              "      <th>skew-BLKA_y</th>\n",
              "      <th>skew-PF_y</th>\n",
              "      <th>skew-PFD_y</th>\n",
              "      <th>slope-MIN_y</th>\n",
              "      <th>slope-FGM_y</th>\n",
              "      <th>slope-FGA_y</th>\n",
              "      <th>slope-FG_PCT_y</th>\n",
              "      <th>slope-FG3M_y</th>\n",
              "      <th>slope-FG3A_y</th>\n",
              "      <th>slope-FG3_PCT_y</th>\n",
              "      <th>slope-OREB_y</th>\n",
              "      <th>slope-DREB_y</th>\n",
              "      <th>slope-AST_y</th>\n",
              "      <th>slope-TOV_y</th>\n",
              "      <th>slope-STL_y</th>\n",
              "      <th>slope-BLK_y</th>\n",
              "      <th>slope-BLKA_y</th>\n",
              "      <th>slope-PF_y</th>\n",
              "      <th>slope-PFD_y</th>\n",
              "      <th>season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21200001</td>\n",
              "      <td>1610612739</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2012-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21200001</td>\n",
              "      <td>1610612764</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2012-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21200002</td>\n",
              "      <td>1610612738</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2012-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21200002</td>\n",
              "      <td>1610612748</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2012-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21200003</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2012-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17213</th>\n",
              "      <td>21801228</td>\n",
              "      <td>1610612750</td>\n",
              "      <td>0</td>\n",
              "      <td>19.361383</td>\n",
              "      <td>0.132194</td>\n",
              "      <td>0.315390</td>\n",
              "      <td>0.380880</td>\n",
              "      <td>0.037270</td>\n",
              "      <td>0.127247</td>\n",
              "      <td>0.243405</td>\n",
              "      <td>0.033172</td>\n",
              "      <td>0.112021</td>\n",
              "      <td>0.080377</td>\n",
              "      <td>0.044467</td>\n",
              "      <td>0.029434</td>\n",
              "      <td>0.015078</td>\n",
              "      <td>0.015604</td>\n",
              "      <td>0.077246</td>\n",
              "      <td>0.057222</td>\n",
              "      <td>18.792583</td>\n",
              "      <td>0.125073</td>\n",
              "      <td>0.299250</td>\n",
              "      <td>0.371700</td>\n",
              "      <td>0.022587</td>\n",
              "      <td>0.105420</td>\n",
              "      <td>0.137400</td>\n",
              "      <td>0.012724</td>\n",
              "      <td>0.093823</td>\n",
              "      <td>0.056565</td>\n",
              "      <td>0.017737</td>\n",
              "      <td>0.018993</td>\n",
              "      <td>0.004449</td>\n",
              "      <td>0.004297</td>\n",
              "      <td>0.053086</td>\n",
              "      <td>0.043862</td>\n",
              "      <td>6.241161</td>\n",
              "      <td>0.083894</td>\n",
              "      <td>0.145602</td>\n",
              "      <td>0.221011</td>\n",
              "      <td>0.045109</td>\n",
              "      <td>...</td>\n",
              "      <td>0.260141</td>\n",
              "      <td>0.139548</td>\n",
              "      <td>0.152345</td>\n",
              "      <td>0.078089</td>\n",
              "      <td>0.084318</td>\n",
              "      <td>0.253873</td>\n",
              "      <td>0.207197</td>\n",
              "      <td>-0.127689</td>\n",
              "      <td>0.083076</td>\n",
              "      <td>0.254805</td>\n",
              "      <td>-0.086416</td>\n",
              "      <td>0.644070</td>\n",
              "      <td>0.745650</td>\n",
              "      <td>0.376980</td>\n",
              "      <td>0.905082</td>\n",
              "      <td>0.489705</td>\n",
              "      <td>0.774043</td>\n",
              "      <td>0.790287</td>\n",
              "      <td>1.128150</td>\n",
              "      <td>1.518941</td>\n",
              "      <td>1.020272</td>\n",
              "      <td>1.173973</td>\n",
              "      <td>0.902004</td>\n",
              "      <td>-0.025346</td>\n",
              "      <td>-0.000829</td>\n",
              "      <td>-0.001017</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.000877</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>0.003891</td>\n",
              "      <td>0.000335</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.000328</td>\n",
              "      <td>0.000475</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000367</td>\n",
              "      <td>-0.000103</td>\n",
              "      <td>-0.000145</td>\n",
              "      <td>-0.000298</td>\n",
              "      <td>2018-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17214</th>\n",
              "      <td>21801229</td>\n",
              "      <td>1610612746</td>\n",
              "      <td>1</td>\n",
              "      <td>20.961103</td>\n",
              "      <td>0.151097</td>\n",
              "      <td>0.338762</td>\n",
              "      <td>0.415462</td>\n",
              "      <td>0.039138</td>\n",
              "      <td>0.109615</td>\n",
              "      <td>0.245792</td>\n",
              "      <td>0.040193</td>\n",
              "      <td>0.150655</td>\n",
              "      <td>0.089595</td>\n",
              "      <td>0.052664</td>\n",
              "      <td>0.036256</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.024566</td>\n",
              "      <td>0.101731</td>\n",
              "      <td>0.079203</td>\n",
              "      <td>20.632115</td>\n",
              "      <td>0.145035</td>\n",
              "      <td>0.315797</td>\n",
              "      <td>0.402731</td>\n",
              "      <td>0.028982</td>\n",
              "      <td>0.103150</td>\n",
              "      <td>0.200885</td>\n",
              "      <td>0.026961</td>\n",
              "      <td>0.131999</td>\n",
              "      <td>0.076913</td>\n",
              "      <td>0.038352</td>\n",
              "      <td>0.014507</td>\n",
              "      <td>0.008561</td>\n",
              "      <td>0.010483</td>\n",
              "      <td>0.092550</td>\n",
              "      <td>0.070324</td>\n",
              "      <td>5.061526</td>\n",
              "      <td>0.086694</td>\n",
              "      <td>0.145580</td>\n",
              "      <td>0.220552</td>\n",
              "      <td>0.041506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.332106</td>\n",
              "      <td>0.315808</td>\n",
              "      <td>0.107324</td>\n",
              "      <td>0.103632</td>\n",
              "      <td>0.108946</td>\n",
              "      <td>0.322670</td>\n",
              "      <td>0.297192</td>\n",
              "      <td>0.619667</td>\n",
              "      <td>0.867317</td>\n",
              "      <td>0.527797</td>\n",
              "      <td>0.554667</td>\n",
              "      <td>1.312994</td>\n",
              "      <td>1.250268</td>\n",
              "      <td>0.793487</td>\n",
              "      <td>1.578490</td>\n",
              "      <td>1.338452</td>\n",
              "      <td>1.766567</td>\n",
              "      <td>1.930366</td>\n",
              "      <td>1.096694</td>\n",
              "      <td>1.961869</td>\n",
              "      <td>2.658826</td>\n",
              "      <td>1.349614</td>\n",
              "      <td>2.096273</td>\n",
              "      <td>-0.167041</td>\n",
              "      <td>-0.001050</td>\n",
              "      <td>-0.003967</td>\n",
              "      <td>-0.004520</td>\n",
              "      <td>0.000491</td>\n",
              "      <td>-0.000524</td>\n",
              "      <td>0.001919</td>\n",
              "      <td>0.000299</td>\n",
              "      <td>-0.003458</td>\n",
              "      <td>-0.001321</td>\n",
              "      <td>-0.003376</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>-0.001002</td>\n",
              "      <td>-0.001588</td>\n",
              "      <td>2018-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17215</th>\n",
              "      <td>21801229</td>\n",
              "      <td>1610612762</td>\n",
              "      <td>0</td>\n",
              "      <td>13.274367</td>\n",
              "      <td>0.126278</td>\n",
              "      <td>0.290592</td>\n",
              "      <td>0.366590</td>\n",
              "      <td>0.055039</td>\n",
              "      <td>0.150691</td>\n",
              "      <td>0.227175</td>\n",
              "      <td>0.032157</td>\n",
              "      <td>0.147787</td>\n",
              "      <td>0.072657</td>\n",
              "      <td>0.045439</td>\n",
              "      <td>0.020937</td>\n",
              "      <td>0.014588</td>\n",
              "      <td>0.009632</td>\n",
              "      <td>0.070785</td>\n",
              "      <td>0.047170</td>\n",
              "      <td>11.892583</td>\n",
              "      <td>0.098810</td>\n",
              "      <td>0.241556</td>\n",
              "      <td>0.333250</td>\n",
              "      <td>0.032005</td>\n",
              "      <td>0.124473</td>\n",
              "      <td>0.173800</td>\n",
              "      <td>0.005507</td>\n",
              "      <td>0.096944</td>\n",
              "      <td>0.036621</td>\n",
              "      <td>0.018554</td>\n",
              "      <td>0.006173</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041548</td>\n",
              "      <td>0.018467</td>\n",
              "      <td>5.122957</td>\n",
              "      <td>0.122347</td>\n",
              "      <td>0.188613</td>\n",
              "      <td>0.286172</td>\n",
              "      <td>0.077617</td>\n",
              "      <td>...</td>\n",
              "      <td>0.244495</td>\n",
              "      <td>0.208018</td>\n",
              "      <td>0.200948</td>\n",
              "      <td>0.112208</td>\n",
              "      <td>0.119546</td>\n",
              "      <td>0.285453</td>\n",
              "      <td>0.227007</td>\n",
              "      <td>0.332416</td>\n",
              "      <td>0.825748</td>\n",
              "      <td>0.654722</td>\n",
              "      <td>0.335020</td>\n",
              "      <td>1.461557</td>\n",
              "      <td>0.687782</td>\n",
              "      <td>1.138355</td>\n",
              "      <td>1.580805</td>\n",
              "      <td>0.708016</td>\n",
              "      <td>0.655690</td>\n",
              "      <td>1.128991</td>\n",
              "      <td>1.440541</td>\n",
              "      <td>1.669923</td>\n",
              "      <td>1.047640</td>\n",
              "      <td>0.677944</td>\n",
              "      <td>0.890988</td>\n",
              "      <td>0.031823</td>\n",
              "      <td>-0.001547</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>-0.003484</td>\n",
              "      <td>-0.000332</td>\n",
              "      <td>-0.000161</td>\n",
              "      <td>-0.000267</td>\n",
              "      <td>0.001180</td>\n",
              "      <td>-0.000113</td>\n",
              "      <td>-0.001886</td>\n",
              "      <td>-0.001639</td>\n",
              "      <td>0.000922</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000263</td>\n",
              "      <td>-0.000173</td>\n",
              "      <td>2018-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17216</th>\n",
              "      <td>21801230</td>\n",
              "      <td>1610612757</td>\n",
              "      <td>1</td>\n",
              "      <td>10.339347</td>\n",
              "      <td>0.119768</td>\n",
              "      <td>0.303181</td>\n",
              "      <td>0.318333</td>\n",
              "      <td>0.029581</td>\n",
              "      <td>0.128369</td>\n",
              "      <td>0.158867</td>\n",
              "      <td>0.036489</td>\n",
              "      <td>0.128982</td>\n",
              "      <td>0.052526</td>\n",
              "      <td>0.055266</td>\n",
              "      <td>0.010580</td>\n",
              "      <td>0.020271</td>\n",
              "      <td>0.022952</td>\n",
              "      <td>0.094450</td>\n",
              "      <td>0.058871</td>\n",
              "      <td>9.582361</td>\n",
              "      <td>0.061888</td>\n",
              "      <td>0.286859</td>\n",
              "      <td>0.244083</td>\n",
              "      <td>0.011169</td>\n",
              "      <td>0.082867</td>\n",
              "      <td>0.055500</td>\n",
              "      <td>0.010876</td>\n",
              "      <td>0.096571</td>\n",
              "      <td>0.024695</td>\n",
              "      <td>0.004406</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011536</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.059965</td>\n",
              "      <td>0.033327</td>\n",
              "      <td>4.940554</td>\n",
              "      <td>0.137944</td>\n",
              "      <td>0.217509</td>\n",
              "      <td>0.281930</td>\n",
              "      <td>0.052800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.234408</td>\n",
              "      <td>0.204037</td>\n",
              "      <td>0.150390</td>\n",
              "      <td>0.092688</td>\n",
              "      <td>0.131643</td>\n",
              "      <td>0.274716</td>\n",
              "      <td>0.216321</td>\n",
              "      <td>0.158577</td>\n",
              "      <td>0.772159</td>\n",
              "      <td>0.392127</td>\n",
              "      <td>0.215070</td>\n",
              "      <td>1.347992</td>\n",
              "      <td>0.577690</td>\n",
              "      <td>1.071509</td>\n",
              "      <td>1.759087</td>\n",
              "      <td>0.471231</td>\n",
              "      <td>0.582341</td>\n",
              "      <td>1.340195</td>\n",
              "      <td>1.335446</td>\n",
              "      <td>1.647062</td>\n",
              "      <td>1.901383</td>\n",
              "      <td>0.823278</td>\n",
              "      <td>0.726314</td>\n",
              "      <td>0.090020</td>\n",
              "      <td>-0.002632</td>\n",
              "      <td>-0.005584</td>\n",
              "      <td>-0.002647</td>\n",
              "      <td>-0.000152</td>\n",
              "      <td>-0.001715</td>\n",
              "      <td>0.003636</td>\n",
              "      <td>-0.001172</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>-0.000232</td>\n",
              "      <td>-0.000003</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>-0.000165</td>\n",
              "      <td>0.000699</td>\n",
              "      <td>2018-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17217</th>\n",
              "      <td>21801230</td>\n",
              "      <td>1610612758</td>\n",
              "      <td>0</td>\n",
              "      <td>20.378090</td>\n",
              "      <td>0.152009</td>\n",
              "      <td>0.342866</td>\n",
              "      <td>0.402185</td>\n",
              "      <td>0.038015</td>\n",
              "      <td>0.110280</td>\n",
              "      <td>0.232442</td>\n",
              "      <td>0.041534</td>\n",
              "      <td>0.131937</td>\n",
              "      <td>0.084763</td>\n",
              "      <td>0.049537</td>\n",
              "      <td>0.032121</td>\n",
              "      <td>0.013964</td>\n",
              "      <td>0.020534</td>\n",
              "      <td>0.091144</td>\n",
              "      <td>0.077389</td>\n",
              "      <td>20.508910</td>\n",
              "      <td>0.137749</td>\n",
              "      <td>0.317655</td>\n",
              "      <td>0.383885</td>\n",
              "      <td>0.027876</td>\n",
              "      <td>0.100176</td>\n",
              "      <td>0.181692</td>\n",
              "      <td>0.027823</td>\n",
              "      <td>0.124329</td>\n",
              "      <td>0.073259</td>\n",
              "      <td>0.031072</td>\n",
              "      <td>0.016785</td>\n",
              "      <td>0.003285</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.080377</td>\n",
              "      <td>0.067256</td>\n",
              "      <td>5.537373</td>\n",
              "      <td>0.094505</td>\n",
              "      <td>0.136431</td>\n",
              "      <td>0.212056</td>\n",
              "      <td>0.041079</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318837</td>\n",
              "      <td>0.318710</td>\n",
              "      <td>0.103520</td>\n",
              "      <td>0.115571</td>\n",
              "      <td>0.283092</td>\n",
              "      <td>0.376867</td>\n",
              "      <td>0.303439</td>\n",
              "      <td>0.635238</td>\n",
              "      <td>0.949801</td>\n",
              "      <td>0.273860</td>\n",
              "      <td>0.382133</td>\n",
              "      <td>1.808255</td>\n",
              "      <td>0.879894</td>\n",
              "      <td>2.075296</td>\n",
              "      <td>1.930601</td>\n",
              "      <td>1.052812</td>\n",
              "      <td>1.934193</td>\n",
              "      <td>1.594135</td>\n",
              "      <td>1.589563</td>\n",
              "      <td>1.324530</td>\n",
              "      <td>3.084273</td>\n",
              "      <td>1.197566</td>\n",
              "      <td>1.670729</td>\n",
              "      <td>0.116440</td>\n",
              "      <td>-0.000692</td>\n",
              "      <td>-0.003762</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>-0.000898</td>\n",
              "      <td>-0.002989</td>\n",
              "      <td>-0.003153</td>\n",
              "      <td>-0.001862</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>-0.001312</td>\n",
              "      <td>-0.000527</td>\n",
              "      <td>-0.000357</td>\n",
              "      <td>-0.000491</td>\n",
              "      <td>0.001376</td>\n",
              "      <td>-0.000336</td>\n",
              "      <td>-0.000322</td>\n",
              "      <td>2018-19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17218 rows × 230 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        GAME_ID   TEAM_ID_x  WIN_x  ...  slope-PF_y  slope-PFD_y   season\n",
              "0      21200001  1610612739      1  ...    0.000000     0.000000  2012-13\n",
              "1      21200001  1610612764      0  ...    0.000000     0.000000  2012-13\n",
              "2      21200002  1610612738      0  ...    0.000000     0.000000  2012-13\n",
              "3      21200002  1610612748      1  ...    0.000000     0.000000  2012-13\n",
              "4      21200003  1610612742      1  ...    0.000000     0.000000  2012-13\n",
              "...         ...         ...    ...  ...         ...          ...      ...\n",
              "17213  21801228  1610612750      0  ...   -0.000145    -0.000298  2018-19\n",
              "17214  21801229  1610612746      1  ...   -0.001002    -0.001588  2018-19\n",
              "17215  21801229  1610612762      0  ...    0.000263    -0.000173  2018-19\n",
              "17216  21801230  1610612757      1  ...   -0.000165     0.000699  2018-19\n",
              "17217  21801230  1610612758      0  ...   -0.000336    -0.000322  2018-19\n",
              "\n",
              "[17218 rows x 230 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwGFiZy5552h",
        "colab_type": "text"
      },
      "source": [
        "# LLE Features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrLMae8DJe9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_columns = ['MIN','FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'OREB', 'DREB', 'AST', 'TOV', 'STL', 'BLK', 'BLKA', 'PF', 'PFD']\n",
        "ts_num = 40\n",
        "\n",
        "plr_df = make_ts(players.sort_values(by=['PLAYER_ID', 'GAME_ID']), \n",
        "        id_column='PLAYER_ID', \n",
        "        columns_for_ts=ts_columns,\n",
        "        columns_to_keep=['TEAM_ID', 'GAME_ID', 'WIN', 'season'], \n",
        "        num_of_shifts=ts_num,\n",
        "        if_nan=np.nan)\n",
        "\n",
        "plr_40_ts = plr_df.dropna()\n",
        "plr_40_ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psV-s-jN4Evx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seasons = ['20'+str(i-1)+'-'+str(i) for i in range(13,20)]\n",
        "all_season_ts = pd.DataFrame()\n",
        "\n",
        "for s in seasons:\n",
        "  X = colapse_ts(get_players_ts(df_by_season(players, s)))\n",
        "  X['season'] = s\n",
        "  all_season_ts = pd.concat([all_season_ts, X])\n",
        "\n",
        "all_season_ts.to_csv('drive/My Drive/SL Project/all_seasons_players_ts.csv')\n",
        "all_season_ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KG-bP17rgV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seasons = ['20'+str(i-1)+'-'+str(i) for i in range(13,20)]\n",
        "\n",
        "reduce_to = 25\n",
        "n_neighbors = 20\n",
        "\n",
        "lle_train_df = pd.concat([\n",
        "                  get_colapsed(seasons[0]).drop(columns=['PLAYER_ID'])]) #,\n",
        "                  #get_colapsed(seasons[0])])\n",
        "                  #get_colapsed(seasons[1]).drop(columns=['PLAYER_ID'])])\n",
        "                  #colapse_ts(get_players_ts(df_by_season(players, seasons[0]))),\n",
        "                  #colapse_ts(get_players_ts(df_by_season(players, seasons[1])))])\n",
        "                  #colapse_ts(get_players_ts(df_by_season(players, seasons[0]))).drop(columns=['PLAYER_ID']),\n",
        "                  #colapse_ts(get_players_ts(df_by_season(players, seasons[1]))).drop(columns=['PLAYER_ID'])])\n",
        "\n",
        "#lle_train_df = df_by_season(plr_40_ts, seasons[0]).drop(columns=['TEAM_ID', 'GAME_ID', 'WIN', 'season', 'PLAYER_ID'])\n",
        "\n",
        "lle_space = get_lle_space(lle_train_df, reduce_to, n_neighbors)\n",
        "\n",
        "\n",
        "\n",
        "collection = []\n",
        "\n",
        "full_comp_df = pd.DataFrame()\n",
        "\n",
        "for i in range(0, 5): #len(seasons)-1):\n",
        "  print(i)\n",
        "  season_for_embeddings = seasons[i+1]\n",
        "  season_for_training = seasons[i+1]\n",
        "  test_season = seasons[i+2]\n",
        "  \n",
        "  \n",
        "  player_embeddings = get_players_embeddings(lle_space, season_for_embeddings, reduce_to, n_neighbors)\n",
        "\n",
        "  #print(player_embeddings)\n",
        "\n",
        "  arr = [seasons[i+2]]\n",
        "  for s in [season_for_training, test_season]:\n",
        "    tmp_df = df_by_season(players, s)[['PLAYER_ID', 'GAME_ID', 'TEAM_ID', 'WIN', \n",
        "                                       #'inactive_score'\n",
        "                                       ]].merge(\n",
        "        player_embeddings, how='left', on='PLAYER_ID')\n",
        "    \n",
        "    tmp_df = comparison_dataframe(tmp_df)\n",
        "    tmp_df['season'] = s\n",
        "\n",
        "    # merge Lev's features\n",
        "    tmp_df = tmp_df.merge(lev_df, how='left', on=['GAME_ID', 'TEAM_ID_x', 'TEAM_ID_y'])\n",
        "    tmp_df = tmp_df.merge(games_df, how='left', on=['GAME_ID', 'TEAM_ID_x'])\n",
        "    tmp_df = tmp_df.merge(comparison_dataframe(players[['GAME_ID', 'TEAM_ID' , 'inactive_score', 'PLAYER_ID']]),\n",
        "                   how='left', on=['GAME_ID', 'TEAM_ID_x']).sort_values(['GAME_ID', 'TEAM_ID_x'])\n",
        "    \n",
        "    arr += make_x_y(tmp_df)\n",
        "\n",
        "  collection.append(tuple(arr))\n",
        "\n",
        "#full_comp_df\n",
        "collection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSouEmxskO6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt6azxdfkP_3",
        "colab_type": "text"
      },
      "source": [
        "# Concat all features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRMy80r0aceZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lev_df = pd.read_csv('drive/My Drive/SL Project/LEV_2012_2019_features.csv').drop(columns=['SEASON', 'GAME_DATE', 'LABLE', 'Unnamed: 0'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9ffgoNbkdpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWbnijxyUsls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Game features\n",
        "games_df = pd.read_csv('drive/My Drive/SL Project/games_with_staff_changes_score.csv', engine='python')\n",
        "games_df = games_df[['GAME_ID', 'TEAM_ID', 'num_loose_before', 'num_win_before', 'prev_matchup_win', 'prev_matchup_loose', 'staff_changes_score']]\n",
        "games_df['played_games'] = games_df['num_loose_before'] + games_df['num_win_before']\n",
        "\n",
        "for col in ['num_loose_before', 'num_win_before']:\n",
        "  #games_df[col] = (games_df[col] + 1) / (games_df['played_games'] + 1)\n",
        "  games_df[col] = (games_df[col]) / (games_df['played_games'])\n",
        "  games_df[col] = games_df[col].replace(np.nan, 0)\n",
        "\n",
        "games_df['part_of_season'] = 0\n",
        "games_df['part_of_season'] += 1*(games_df['played_games'] < 2)\n",
        "games_df['part_of_season'] += 2*((games_df['played_games'] >= 2) & (games_df['played_games'] <= 70))\n",
        "#games_df = games_df.merge(games_ts_df[['GAME_ID', 'TEAM_ID', 'win_hist_type']], how='left', on=['GAME_ID', 'TEAM_ID'])\n",
        "games_df.drop(columns=['played_games'], inplace=True)\n",
        "\n",
        "\n",
        "games_df = games_df.merge(games_df, how='inner', on='GAME_ID').sort_values(by=['GAME_ID'])\n",
        "games_df = games_df.query('TEAM_ID_x != TEAM_ID_y')\n",
        "games_df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viTVYQkmkUyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_comp_df = full_comp_df.merge(lev_df, how='left', on=['GAME_ID', 'TEAM_ID_x', 'TEAM_ID_y']).sort_values(['GAME_ID', 'TEAM_ID_x'])\n",
        "full_comp_df = full_comp_df.merge(games_df, how='left', on=['GAME_ID', 'TEAM_ID_x']).sort_values(['GAME_ID', 'TEAM_ID_x'])\n",
        "full_comp_df = full_comp_df.merge(comparison_dataframe(players[['GAME_ID', 'TEAM_ID' , 'inactive_score', 'PLAYER_ID']]),\n",
        "                   how='left', on=['GAME_ID', 'TEAM_ID_x']).sort_values(['GAME_ID', 'TEAM_ID_x'])\n",
        "\n",
        "full_comp_df = full_comp_df.dropna()\n",
        "\n",
        "collection = make_collection(full_comp_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lWiIpYTRj8T",
        "colab_type": "text"
      },
      "source": [
        "# Training by seasons "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH7xRXRpzHPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mul_train(data, model_func, roc_auc=False, keep_only=None, conseq=False, no_train=False):\n",
        "  res = []\n",
        "  preds = []\n",
        "  train_accuracy, accuracy = 0, 0\n",
        "  prev_X_train, prev_y_train = None, None\n",
        "  stat = [] \n",
        "\n",
        "  for label, X_train, y_train, X_test, y_test in data:\n",
        "    if keep_only is not None:\n",
        "      X_train = X_train[keep_only]\n",
        "      X_test = X_test[keep_only]\n",
        "    \n",
        "    if conseq and prev_X_train is not None:\n",
        "      X_train = pd.concat([prev_X_train, X_train])\n",
        "      y_train = pd.concat([prev_y_train, y_train])\n",
        "\n",
        "    model = model_func(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    if not no_train:\n",
        "      y_train_pred = model.predict(X_train)\n",
        "\n",
        "    prev_X_train, prev_y_train = X_train, y_train\n",
        "    \n",
        "    if roc_auc:\n",
        "      #acc = metrics.roc_auc_score(y_test, y_pred)\n",
        "      acc = max_accuracy(y_test, y_pred)\n",
        "      if not no_train:\n",
        "        train_acc = max_accuracy(y_train, y_train_pred)\n",
        "    else:\n",
        "      acc = np.mean(y_pred == y_test.values)\n",
        "      if not no_train:\n",
        "        train_acc = np.mean(y_train_pred == y_train.values)\n",
        "    \n",
        "    accuracy += acc / len(data)\n",
        "    \n",
        "    if not no_train:\n",
        "      train_accuracy += train_acc / len(data)\n",
        "    else:\n",
        "      train_accuracy = 0\n",
        "      train_acc = 0\n",
        "\n",
        "    stat.append([label, train_acc, acc])\n",
        "    print('{} train = {}, test = {}'.format(label, train_acc, acc))\n",
        "    res.append(model)\n",
        "    preds.append((y_pred, y_test))\n",
        "\n",
        "  print('Avarage accuracy: train = {}, test = {}'.format(train_accuracy, accuracy))\n",
        "  stat.append(['Total', train_accuracy, accuracy])\n",
        "  stat = pd.DataFrame(stat, columns=['season', 'train', 'test'])\n",
        "\n",
        "  return res, X_train.columns, preds, accuracy, stat\n",
        "\n",
        "def forest_func(X_train, y_train):\n",
        "  return ParaForest(X_train, y_train, {'n_estimators': 300, 'oob_score': True , 'n_jobs': 4, 'max_depth' : 4})\n",
        "\n",
        "def linear_svm_func(X_train, y_train):\n",
        "  cls = make_pipeline(StandardScaler(), LinearSVC(random_state=0, tol=1e-5, max_iter=2000, C=0.0001))\n",
        "  #cls = make_pipeline(StandardScaler(), NuSVC(nu=0.9))\n",
        "  return cls.fit(X_train, y_train)\n",
        "\n",
        "def svm_func(X_train, y_train):\n",
        "  cls = make_pipeline(StandardScaler(), SVC(random_state=0,  C=1))\n",
        "  #cls = make_pipeline(StandardScaler(), NuSVC(nu=0.9))\n",
        "  return cls.fit(X_train, y_train)\n",
        "\n",
        "def lr_func(X_train, y_train):\n",
        "  return Ridge(random_state=1, alpha=1, normalize=True).fit(X_train, y_train)\n",
        "  #return Lasso(random_state=1, alpha=0.0001, max_iter=10000, normalize=True).fit(X_train, y_train)\n",
        "  \n",
        "def logistic_func(X_train, y_train):\n",
        "  #penalty='elasticnet', 'l1'\n",
        "  X = normalize(X_train)\n",
        "  return LogisticRegression(random_state=0, penalty='l2', C=100).fit(X_train, y_train)\n",
        "\n",
        "def tree_func(X_train, y_train):\n",
        "  return DecisionTreeClassifier(criterion=\"entropy\", max_depth=3).fit(X_train, y_train)\n",
        "\n",
        "def lda_func(X_train, y_train):\n",
        "  return LinearDiscriminantAnalysis(solver='svd',  tol=0.001).fit(X_train, y_train)\n",
        "\n",
        "conseq = False\n",
        "#keep_only = None\n",
        "#models, cols, preds, av_accuracy, stat_df = mul_train(collection, svm_func, conseq=conseq, keep_only=keep_only)\n",
        "#models, cols, preds, av_accuracy, stat_df = mul_train(collection, lr_func, True, conseq=conseq, keep_only=keep_only, no_train=True)\n",
        "models, cols, preds, av_accuracy, stat_df = mul_train(collection, forest_func, conseq=conseq, keep_only=keep_only)\n",
        "#models, cols, preds, av_accuracy, stat_df = mul_train(collection, logistic_func, True, conseq=conseq)\n",
        "#models, cols, preds, av_accuracy, stat_df = mul_train(collection, tree_func, conseq=conseq)#, keep_only=keep_only)\n",
        "#models, cols, preds, av_accuracy, stat_df = mul_train(collection, lda_func, conseq=conseq)#, keep_only=keep_only)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dzw6_mbiWxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QbxtVEDiG2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_dump = {\n",
        "    'preds': preds, \n",
        "    'cols': cols,\n",
        "    'stat': stat_df.values\n",
        "}\n",
        "dump(to_dump, open('drive/My Drive/SL Project/output/[C]kmeans_forest.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8F_S0ZOiNF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pf_res = models\n",
        "d = defaultdict(float)\n",
        "for i in range(len(pf_res)):\n",
        "  for key, val in dict(zip(cols, list(pf_res[i].model.feature_importances_))).items():\n",
        "    d[key] += val/len(pf_res)\n",
        "\n",
        "import_df = pd.DataFrame(d.items(), columns=['feature', 'importance']).sort_values(by=['importance'], ascending=False).reset_index(drop=True)\n",
        "plot_feature_importances(import_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUipvPv-iXii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2_PE2Rq5Ji5",
        "colab_type": "text"
      },
      "source": [
        "### Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stGlQ-1Ybx5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a51a802-4031-4108-d34c-3d7c94ee85e9"
      },
      "source": [
        "pf_res = models\n",
        "d = defaultdict(float)\n",
        "for i in range(len(pf_res)):\n",
        "  for key, val in dict(zip(cols, list(pf_res[i].model.feature_importances_))).items():\n",
        "    d[key] += val/len(pf_res)\n",
        "\n",
        "import_df = pd.DataFrame(d.items(), columns=['feature', 'importance']).sort_values(by=['importance'], ascending=False).reset_index(drop=True)\n",
        "plot_feature_importances(import_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>num_win_before_x</td>\n",
              "      <td>0.116363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>num_win_before_y</td>\n",
              "      <td>0.114312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dist_away</td>\n",
              "      <td>0.045025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FG_PCT_x</td>\n",
              "      <td>0.040612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FG_PCT_y</td>\n",
              "      <td>0.039769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>FGM_x</td>\n",
              "      <td>0.039209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>FGM_y</td>\n",
              "      <td>0.038983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AST_y</td>\n",
              "      <td>0.036104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AST_x</td>\n",
              "      <td>0.035562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>HOME_LABLE</td>\n",
              "      <td>0.033842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>STL_y</td>\n",
              "      <td>0.024513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>STL_x</td>\n",
              "      <td>0.024189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PFD_y</td>\n",
              "      <td>0.023698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PFD_x</td>\n",
              "      <td>0.023582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>MIN_x</td>\n",
              "      <td>0.023438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>MIN_y</td>\n",
              "      <td>0.023377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>FG3M_x</td>\n",
              "      <td>0.022040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>FG3M_y</td>\n",
              "      <td>0.021063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>FG3_PCT_y</td>\n",
              "      <td>0.020987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>FG3_PCT_x</td>\n",
              "      <td>0.018920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>DREB_x</td>\n",
              "      <td>0.018263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>DREB_y</td>\n",
              "      <td>0.018260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>FGA_y</td>\n",
              "      <td>0.017850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>FGA_x</td>\n",
              "      <td>0.017381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>staff_changes_score_y</td>\n",
              "      <td>0.016151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>staff_changes_score_x</td>\n",
              "      <td>0.016000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>BLK_x</td>\n",
              "      <td>0.013777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>BLK_y</td>\n",
              "      <td>0.013733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>FG3A_y</td>\n",
              "      <td>0.012915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>FG3A_x</td>\n",
              "      <td>0.011964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>BLKA_y</td>\n",
              "      <td>0.009733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>BLKA_x</td>\n",
              "      <td>0.009340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>TOV_x</td>\n",
              "      <td>0.008324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>TOV_y</td>\n",
              "      <td>0.008274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>std_all_dist</td>\n",
              "      <td>0.007731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PF_x</td>\n",
              "      <td>0.007555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>PF_y</td>\n",
              "      <td>0.006993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>inactive_score_y</td>\n",
              "      <td>0.006979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>OREB_x</td>\n",
              "      <td>0.006677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>OREB_y</td>\n",
              "      <td>0.006510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  feature  importance\n",
              "0        num_win_before_x    0.116363\n",
              "1        num_win_before_y    0.114312\n",
              "2               Dist_away    0.045025\n",
              "3                FG_PCT_x    0.040612\n",
              "4                FG_PCT_y    0.039769\n",
              "5                   FGM_x    0.039209\n",
              "6                   FGM_y    0.038983\n",
              "7                   AST_y    0.036104\n",
              "8                   AST_x    0.035562\n",
              "9              HOME_LABLE    0.033842\n",
              "10                  STL_y    0.024513\n",
              "11                  STL_x    0.024189\n",
              "12                  PFD_y    0.023698\n",
              "13                  PFD_x    0.023582\n",
              "14                  MIN_x    0.023438\n",
              "15                  MIN_y    0.023377\n",
              "16                 FG3M_x    0.022040\n",
              "17                 FG3M_y    0.021063\n",
              "18              FG3_PCT_y    0.020987\n",
              "19              FG3_PCT_x    0.018920\n",
              "20                 DREB_x    0.018263\n",
              "21                 DREB_y    0.018260\n",
              "22                  FGA_y    0.017850\n",
              "23                  FGA_x    0.017381\n",
              "24  staff_changes_score_y    0.016151\n",
              "25  staff_changes_score_x    0.016000\n",
              "26                  BLK_x    0.013777\n",
              "27                  BLK_y    0.013733\n",
              "28                 FG3A_y    0.012915\n",
              "29                 FG3A_x    0.011964\n",
              "30                 BLKA_y    0.009733\n",
              "31                 BLKA_x    0.009340\n",
              "32                  TOV_x    0.008324\n",
              "33                  TOV_y    0.008274\n",
              "34           std_all_dist    0.007731\n",
              "35                   PF_x    0.007555\n",
              "36                   PF_y    0.006993\n",
              "37       inactive_score_y    0.006979\n",
              "38                 OREB_x    0.006677\n",
              "39                 OREB_y    0.006510"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x1440 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euQkSWAiW_Nz",
        "colab_type": "text"
      },
      "source": [
        "# TRAINIGN BY SEASON 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p8h5qGdXCPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_by_max_tresh(y_true, probs):\n",
        "  tresh = max_tresh(y_true, probs)\n",
        "  return (probs > tresh)*1\n",
        "\n",
        "\n",
        "def cross_validation(model, X_train, y_train, X_test, cv_type, test_from_future=False):\n",
        "  n_splits = 20\n",
        "\n",
        "  if cv_type == 1:\n",
        "    kfold = TimeSeriesSplit(n_splits=n_splits)\n",
        "  elif cv_type==2:\n",
        "    kfold = BlockingTimeSeriesSplit(n_splits=n_splits)\n",
        "  else:\n",
        "    kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 50)\n",
        "\n",
        "  inputs_arr = np.array(X_train)\n",
        "  outputs_arr = np.array(y_train).reshape(-1,)\n",
        "  x_test = np.array(X_test)\n",
        "  if test_from_future:\n",
        "    all_y_tests = np.array([])\n",
        "    y_pred = np.array([])\n",
        "  else:\n",
        "    y_pred = np.zeros(x_test.shape[0])\n",
        "  \n",
        "  num_to_test = int(len(inputs_arr) / kfold.n_splits)\n",
        "  pred_results = []\n",
        "  total_accuracy = 0\n",
        "  valid_accuracy = 0\n",
        "  total_test_size = 0\n",
        "  stopped = False\n",
        "\n",
        "  for train_samp, valid_samp in kfold.split(inputs_arr, outputs_arr):\n",
        "    model.fit(inputs_arr[train_samp, :], outputs_arr[train_samp,])\n",
        "    \n",
        "    if test_from_future:\n",
        "      if valid_samp[-1] + num_to_test <= len(inputs_arr):\n",
        "        test_indecies = np.array(range(valid_samp[-1], valid_samp[-1] + num_to_test))\n",
        "      else:\n",
        "        break\n",
        "       \n",
        "      x_test = inputs_arr[test_indecies, :]\n",
        "      y_test = outputs_arr[test_indecies,]\n",
        "      all_y_tests = np.append(all_y_tests, y_test)\n",
        "\n",
        "      part_pred = model.predict(x_test)\n",
        "      y_pred = np.append(y_pred, convert_by_max_tresh(y_test, part_pred))\n",
        "\n",
        "      pred_results.append((y_test, part_pred))\n",
        "      acc = max_accuracy(y_test, part_pred)\n",
        "      total_test_size += len(part_pred)\n",
        "      total_accuracy += acc\n",
        "      valid_accuracy = max_accuracy(outputs_arr[valid_samp,], model.predict(inputs_arr[valid_samp, :]))\n",
        "    else:\n",
        "      print('Valid score: ', max_accuracy(outputs_arr[valid_samp,], model.predict(inputs_arr[valid_samp, :])))\n",
        "      y_pred += model.predict(x_test) / kfold.n_splits\n",
        "  \n",
        "  #print(total_accuracy /(len(pred_results)+1))\n",
        "  total_accuracy = total_accuracy/len(pred_results)\n",
        "  print('Valid accuracy: {}, Test accuracy: {}, test size: {}'.format(valid_accuracy, total_accuracy, total_test_size))\n",
        "  return y_pred, all_y_tests, total_accuracy\n",
        "\n",
        "def cross_mul_train(data, model_func, roc_auc=False, keep_only=None, conseq=False, no_train=False, test_from_future=False, cv_type=1):\n",
        "  res = []\n",
        "  preds = []\n",
        "  train_accuracy, accuracy = 0, 0\n",
        "  prev_X_train, prev_y_train = None, None\n",
        "  stat = [] \n",
        "  cols = []\n",
        "\n",
        "  for label, X_train, y_train, X_test, y_test in data:\n",
        "    if keep_only is not None:\n",
        "      X_train = X_train[keep_only]\n",
        "      X_test = X_test[keep_only]\n",
        "    \n",
        "    if conseq and prev_X_train is not None:\n",
        "      X_train = pd.concat([prev_X_train, X_train])\n",
        "      y_train = pd.concat([prev_y_train, y_train])\n",
        "\n",
        "    model = model_func()\n",
        "    \n",
        "    \n",
        "    if test_from_future:\n",
        "      print(label)\n",
        "      y_pred, y_test, acc = cross_validation(model, X_test, y_test, X_test, cv_type, test_from_future=test_from_future)\n",
        "      accuracy += acc / len(data)\n",
        "      \n",
        "      print('==== >Check accuracy: ', max_accuracy(y_test, y_pred))\n",
        "      stat.append([label, 0, acc])\n",
        "    else:\n",
        "      y_pred, _ = cross_validation(model, X_train, y_train, X_test, cv_type, test_from_future=test_from_future)\n",
        "\n",
        "      if not no_train:\n",
        "        y_train_pred = model.predict(X_train)\n",
        "\n",
        "      prev_X_train, prev_y_train = X_train, y_train\n",
        "      \n",
        "      if roc_auc:\n",
        "        #acc = metrics.roc_auc_score(y_test, y_pred)\n",
        "        acc = max_accuracy(y_test, y_pred)\n",
        "        if not no_train:\n",
        "          train_acc = max_accuracy(y_train, y_train_pred)\n",
        "      else:\n",
        "        acc = np.mean(y_pred == y_test.values)\n",
        "        if not no_train:\n",
        "          train_acc = np.mean(y_train_pred == y_train.values)\n",
        "      \n",
        "      accuracy += acc / len(data)\n",
        "      \n",
        "      if not no_train:\n",
        "        train_accuracy += train_acc / len(data)\n",
        "      else:\n",
        "        train_accuracy = 0\n",
        "        train_acc = 0\n",
        "\n",
        "      stat.append([label, train_acc, acc])\n",
        "      print('{} train = {}, test = {}'.format(label, train_acc, acc))\n",
        "      res.append(model)\n",
        "      cols = X_train.columns\n",
        "      \n",
        "    # Used to store\n",
        "    preds.append((y_pred, y_test))\n",
        "\n",
        "  print('Avarage accuracy: train = {}, test = {}'.format(train_accuracy, accuracy))\n",
        "  stat.append(['Total', train_accuracy, accuracy])\n",
        "  stat = pd.DataFrame(stat, columns=['season', 'train', 'test'])\n",
        "\n",
        "  return res, cols, preds, accuracy, stat\n",
        "\n",
        "def forest_func():\n",
        "  params = {'n_estimators': 800, 'oob_score': True , 'n_jobs': 4, 'max_depth' : 4}\n",
        "  return RandomForestClassifier(**params, random_state=0)\n",
        "  #return ParaForest(params={'n_estimators': 400, 'oob_score': True , 'n_jobs': 4, 'max_depth' : 4}, fit_instantly=False)\n",
        "  #return ParaForest(X_train, y_train, {'n_estimators': 400, 'oob_score': True , 'n_jobs': 4, 'max_depth' : 3})\n",
        "\n",
        "def linear_svm_func():\n",
        "  cls = make_pipeline(StandardScaler(), LinearSVC(random_state=0, tol=1e-5, max_iter=2000, C=0.01))\n",
        "  #cls = make_pipeline(StandardScaler(), NuSVC(nu=0.9))\n",
        "  return cls\n",
        "\n",
        "def svm_func():\n",
        "  cls = make_pipeline(StandardScaler(), SVC(random_state=0, kernel=\"rbf\", C=5))\n",
        "  #cls = make_pipeline(StandardScaler(), NuSVC(nu=0.9))\n",
        "  return cls\n",
        "\n",
        "def lr_func():\n",
        "  return Ridge(random_state=0, alpha=2, normalize=True)\n",
        "  #return Lasso(random_state=1, alpha=0.0001, max_iter=10000, normalize=True)\n",
        "  \n",
        "def logistic_func():\n",
        "  return make_pipeline(StandardScaler(), LogisticRegression(random_state=0, penalty='l2', C=0.01))\n",
        "\n",
        "def tree_func():\n",
        "  return DecisionTreeClassifier(criterion=\"entropy\", max_depth=6)\n",
        "\n",
        "def lda_func():\n",
        "  return LinearDiscriminantAnalysis(solver='svd',  tol=0.001)\n",
        "\n",
        "def qda_func():\n",
        "  return QuadraticDiscriminantAnalysis(reg_param=0.001)\n",
        "\n",
        "def naive_func():\n",
        "  return BernoulliNB()\n",
        "\n",
        "\n",
        "cv_type = 1\n",
        "conseq = False \n",
        "#keep_only = None\n",
        "#_,_, preds,_,stat = cross_mul_train(collection, linear_svm_func, True, conseq=conseq, keep_only=keep_only, no_train=True, test_from_future=True, cv_type=cv_type)#\n",
        "#_,_, preds,_,stat = cross_mul_train(collection, lr_func, True, conseq=conseq, keep_only=keep_only, no_train=True, test_from_future=True, cv_type=cv_type)#\n",
        "#_,_, preds,_,stat = cross_mul_train(collection, forest_func, conseq=conseq, keep_only=keep_only, no_train=True, test_from_future=True, cv_type=cv_type)\n",
        "#_,_, preds,_,stat = cross_mul_train(collection, logistic_func, True, conseq=conseq, keep_only=keep_only, no_train=True, test_from_future=True, cv_type=cv_type)\n",
        "#_,_, preds,_,stat = cross_mul_train(collection, tree_func, True, conseq=conseq, keep_only=keep_only, no_train=True, test_from_future=True, cv_type=cv_type)\n",
        "#_,_, preds,_,stat = cross_mul_train(collection, lda_func, True, conseq=conseq, keep_only=keep_only, no_train=True, test_from_future=True, cv_type=cv_type)\n",
        "#_,_, preds,_,stat = cross_mul_train(collection, qda_func, True, conseq=conseq, keep_only=keep_only, no_train=True, test_from_future=True, cv_type=cv_type)\n",
        "#_,_, preds,_,stat = cross_mul_train(collection, naive_func, True, conseq=conseq, keep_only=keep_only, no_train=True, test_from_future=True, cv_type=cv_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bU-DPi0uUXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "da583d82-5f5c-489f-81db-ffcaff408ee4"
      },
      "source": [
        "cv_type = 1\n",
        "dataset_name = 'kmeans_'\n",
        "for func in [naive_func, qda_func, lda_func, svm_func, lr_func, linear_svm_func, logistic_func, tree_func, forest_func]:\n",
        "  file_name = dataset_name + func.__name__\n",
        "  print()\n",
        "  print(file_name)\n",
        "  _,cols, preds,_,stat = cross_mul_train(collection, func, True, conseq=conseq, keep_only=keep_only, no_train=True, test_from_future=True, cv_type=cv_type)\n",
        "  to_dump = {\n",
        "    'preds': preds, \n",
        "    'cols': cols,\n",
        "    'stat': stat.values\n",
        "    }\n",
        "  break\n",
        "stat.values\n",
        "  #dump(to_dump, open('drive/My Drive/SL Project/output_3/{}.csv'.format(file_name), 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "kmeans_naive_func\n",
            "2014-15\n",
            "Valid accuracy: 0.5213675213675214, Test accuracy: 0.571364046973803, test size: 2214\n",
            "==== >Check accuracy:  0.571364046973803\n",
            "2015-16\n",
            "Valid accuracy: 0.6752136752136753, Test accuracy: 0.5849141824751581, test size: 2214\n",
            "==== >Check accuracy:  0.5849141824751581\n",
            "2016-17\n",
            "Valid accuracy: 0.5555555555555556, Test accuracy: 0.580397470641373, test size: 2214\n",
            "==== >Check accuracy:  0.580397470641373\n",
            "2017-18\n",
            "Valid accuracy: 0.5555555555555556, Test accuracy: 0.5840108401084012, test size: 2214\n",
            "==== >Check accuracy:  0.5840108401084011\n",
            "2018-19\n",
            "Valid accuracy: 0.5384615384615384, Test accuracy: 0.5930442637759712, test size: 2214\n",
            "==== >Check accuracy:  0.5930442637759711\n",
            "Avarage accuracy: train = 0, test = 0.5827461607949413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['2014-15', 0, 0.11427280939476062],\n",
              "       ['2015-16', 0, 0.23125564588979225],\n",
              "       ['2016-17', 0, 0.34733514001806687],\n",
              "       ['2017-18', 0, 0.4641373080397471],\n",
              "       ['2018-19', 0, 0.5827461607949413],\n",
              "       ['Total', 0, 0.5827461607949413]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ1EMqIdilVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SKW34eD7yFN",
        "colab_type": "text"
      },
      "source": [
        "## Major voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlmjS1sK72Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_preds_df(groups, treshold=0.5):\n",
        "  num_groups = len(groups)\n",
        "  preds_matrix, y_list = [], []\n",
        "  for i in range(len(groups[0])):\n",
        "    #preds_matrix += list(zip( *[groups[k][i][0] for k in range(num_groups)] ))\n",
        "    #preds_matrix += list(sum([groups[k][i][0] for k in range(num_groups)] ))\n",
        "    preds_matrix += list(zip( *[groups[k][i][0] for k in range(num_groups)] ))\n",
        "    y_list += list(zip( *[groups[k][i][1] for k in range(num_groups)] ))\n",
        "\n",
        "  majority = num_groups * treshold\n",
        "  res = 1*(np.array(preds_matrix) >= majority)\n",
        "  return preds_matrix, pd.DataFrame(y_list), res\n",
        "\n",
        "def check_y_df(y_df):\n",
        "  for i in range(len(y_df.columns)-1):\n",
        "    if sum(y_df[i] != y_df[i+1]) != 0:\n",
        "      return 'Error in labels'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUIM_ImtxAu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "8b53f626-7840-406e-9692-c79a1358cad8"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "mypath = 'drive/My Drive/SL Project/output_3/'\n",
        "groups = []\n",
        "columns=[]\n",
        "for file_name in [f for f in listdir(mypath) if isfile(join(mypath, f))]:\n",
        "  if '[Blocked]' not in file_name:\n",
        "    columns.append(file_name)\n",
        "    obj = load(open(mypath + file_name, 'rb'))\n",
        "    groups.append(obj['preds'])\n",
        "\n",
        "m, y_df, p_mat = make_preds_df(groups, 0.44)\n",
        "check_y_df(y_df)\n",
        "#print( np.mean(p_mat == y_df[0]))\n",
        "m = pd.DataFrame(m, columns=columns)\n",
        "m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ave_naive_func.csv</th>\n",
              "      <th>ave_qda_func.csv</th>\n",
              "      <th>ave_lda_func.csv</th>\n",
              "      <th>ave_svm_func.csv</th>\n",
              "      <th>ave_lr_func.csv</th>\n",
              "      <th>ave_linear_svm_func.csv</th>\n",
              "      <th>ave_logistic_func.csv</th>\n",
              "      <th>ave_tree_func.csv</th>\n",
              "      <th>ave_forest_func.csv</th>\n",
              "      <th>ts_naive_func.csv</th>\n",
              "      <th>ts_qda_func.csv</th>\n",
              "      <th>ts_lda_func.csv</th>\n",
              "      <th>ts_svm_func.csv</th>\n",
              "      <th>ts_lr_func.csv</th>\n",
              "      <th>ts_linear_svm_func.csv</th>\n",
              "      <th>ts_logistic_func.csv</th>\n",
              "      <th>ts_tree_func.csv</th>\n",
              "      <th>ts_forest_func.csv</th>\n",
              "      <th>kmeans_lr_func.csv</th>\n",
              "      <th>kmeans_linear_svm_func.csv</th>\n",
              "      <th>kmeans_logistic_func.csv</th>\n",
              "      <th>kmeans_tree_func.csv</th>\n",
              "      <th>kmeans_forest_func.csv</th>\n",
              "      <th>lle_naive_func.csv</th>\n",
              "      <th>lle_qda_func.csv</th>\n",
              "      <th>lle_lda_func.csv</th>\n",
              "      <th>lle_svm_func.csv</th>\n",
              "      <th>lle_lr_func.csv</th>\n",
              "      <th>lle_linear_svm_func.csv</th>\n",
              "      <th>lle_logistic_func.csv</th>\n",
              "      <th>lle_tree_func.csv</th>\n",
              "      <th>lle_forest_func.csv</th>\n",
              "      <th>kmeans_naive_func.csv</th>\n",
              "      <th>kmeans_qda_func.csv</th>\n",
              "      <th>kmeans_lda_func.csv</th>\n",
              "      <th>kmeans_svm_func.csv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11065</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11066</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11067</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11068</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11069</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11070 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ave_naive_func.csv  ...  kmeans_svm_func.csv\n",
              "0                     0.0  ...                  0.0\n",
              "1                     0.0  ...                  0.0\n",
              "2                     0.0  ...                  1.0\n",
              "3                     0.0  ...                  0.0\n",
              "4                     0.0  ...                  1.0\n",
              "...                   ...  ...                  ...\n",
              "11065                 0.0  ...                  0.0\n",
              "11066                 1.0  ...                  1.0\n",
              "11067                 0.0  ...                  0.0\n",
              "11068                 1.0  ...                  0.0\n",
              "11069                 0.0  ...                  1.0\n",
              "\n",
              "[11070 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg55WNPgTk6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#k_choice = [13, 22, 31]\n",
        "k_choice = ['ave_lr_func.csv', 'ts_lr_func.csv', 'kmeans_lr_func.csv'] \n",
        "#k_choice = list(range(36))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tdE8P5c2RuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "1c782c04-b0db-41ee-ffab-0a1d48518488"
      },
      "source": [
        "'''\n",
        "m_cp = m.copy()\n",
        "#tresh = 0.5\n",
        "#for k in [1, 2, 12, 13, 16, 17, 24, 25]:\n",
        "for k in [1, 5, 11, 16]:\n",
        "  tresh = max_tresh(y_df[0], m_cp[k])\n",
        "  m_cp[k] = 1*(m_cp[k] > tresh)\n",
        "\n",
        "m_cp.to_csv('drive/My Drive/SL Project/major_vote_2.csv')\n",
        "\n",
        "\n",
        "'''\n",
        "#m_cp = pd.read_csv('drive/My Drive/SL Project/major_vote.csv').drop(columns=['Unnamed: 0'])\n",
        "\n",
        "#m_cp = m_cp[map(lambda x: str(x), [1, 10, 12, 13, 22, 16, 17, 18, 19])] #.drop(columns=removed)\n",
        "m_cp = m[k_choice]\n",
        "for k in range(1, len(m_cp.columns)):\n",
        "  m_cp[m_cp.columns[0]] += m_cp[m_cp.columns[k]]\n",
        "\n",
        "t2 = len(m_cp.columns) * 0.5\n",
        "np.mean(1*(m_cp[m_cp.columns[0]] > t2)  == y_df[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6907859078590786"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}